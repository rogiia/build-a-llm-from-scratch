{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c024bfa4-1a7a-4751-b5a1-827225a3478b",
   "metadata": {
    "id": "c024bfa4-1a7a-4751-b5a1-827225a3478b"
   },
   "source": [
    "<table style=\"width:100%\">\n",
    "<tr>\n",
    "<td style=\"vertical-align:middle; text-align:left;\">\n",
    "<font size=\"2\">\n",
    "Supplementary code for the <a href=\"http://mng.bz/orYv\">Build a Large Language Model From Scratch</a> book by <a href=\"https://sebastianraschka.com\">Sebastian Raschka</a><br>\n",
    "<br>Code repository: <a href=\"https://github.com/rasbt/LLMs-from-scratch\">https://github.com/rasbt/LLMs-from-scratch</a>\n",
    "</font>\n",
    "</td>\n",
    "<td style=\"vertical-align:middle; text-align:left;\">\n",
    "<a href=\"http://mng.bz/orYv\"><img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/cover-small.webp\" width=\"100px\"></a>\n",
    "</td>\n",
    "</tr>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b8c870-fb72-490e-8916-d8129bd5d1ff",
   "metadata": {
    "id": "58b8c870-fb72-490e-8916-d8129bd5d1ff"
   },
   "source": [
    "# Appendix E: Parameter-efficient Finetuning with LoRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b7e01c2-1c84-4f2a-bb51-2e0b74abda90",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5b7e01c2-1c84-4f2a-bb51-2e0b74abda90",
    "outputId": "316166b4-027a-4756-e9b4-fe88ae75dd4f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matplotlib version: 3.10.5\n",
      "numpy version: 2.3.2\n",
      "tiktoken version: 0.11.0\n",
      "torch version: 2.8.0+cu126\n",
      "tensorflow version: 2.20.0\n",
      "pandas version: 2.3.2\n"
     ]
    }
   ],
   "source": [
    "from importlib.metadata import version\n",
    "\n",
    "pkgs = [\"matplotlib\",\n",
    "        \"numpy\",\n",
    "        \"tiktoken\",\n",
    "        \"torch\",\n",
    "        \"tensorflow\", # For OpenAI's pretrained weights\n",
    "        \"pandas\"      # Dataset loading\n",
    "       ]\n",
    "for p in pkgs:\n",
    "    print(f\"{p} version: {version(p)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21532056-0ef4-4c98-82c7-e91f61c6485e",
   "metadata": {
    "id": "21532056-0ef4-4c98-82c7-e91f61c6485e"
   },
   "source": [
    "## E.1 Introduction to LoRA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66edc999-3d91-4a1c-a157-9d056392e8d8",
   "metadata": {
    "id": "66edc999-3d91-4a1c-a157-9d056392e8d8"
   },
   "source": [
    "- No code in this section\n",
    "- Low-rank adaptation (LoRA) is a machine learning technique that modifies a pretrained model to better suit a specific, often smaller, dataset by adjusting only a small, low-rank subset of the model's parameters\n",
    "- This approach is important because it allows for efficient finetuning of large models on task-specific data, significantly reducing the computational cost and time required for finetuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb75b5d-d59c-4948-821a-1594a5883dc1",
   "metadata": {
    "id": "5bb75b5d-d59c-4948-821a-1594a5883dc1"
   },
   "source": [
    "- Suppose we have a large weight matrix $W$ for a given layer\n",
    "- During backpropagation, we learn a $\\Delta W$ matrix, which contains information on how much we want to update the original weights to minimize the loss function during training\n",
    "- In regular training and finetuning, the weight update is defined as follows:\n",
    "\n",
    "$$W_{\\text{updated}} = W + \\Delta W$$\n",
    "\n",
    "- The LoRA method proposed by [Hu et al.](https://arxiv.org/abs/2106.09685) offers a more efficient alternative to computing the weight updates $\\Delta W$ by learning an approximation of it, $\\Delta W \\approx AB$.\n",
    "- In other words, in LoRA, we have the following, where $A$ and $B$ are two small weight matrices:\n",
    "\n",
    "$$W_{\\text{updated}} = W + AB$$\n",
    "\n",
    "- The figure below illustrates these formulas for full finetuning and LoRA side by side"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8a7419d-cae9-4525-bb44-1641f6ef4f3b",
   "metadata": {
    "id": "a8a7419d-cae9-4525-bb44-1641f6ef4f3b"
   },
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/appendix-e_compressed/lora-1.webp\" width=\"500px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4edd43c9-8ec5-48e6-b3fc-5fb3c16037cc",
   "metadata": {
    "id": "4edd43c9-8ec5-48e6-b3fc-5fb3c16037cc"
   },
   "source": [
    "- If you paid close attention, the full finetuning and LoRA depictions in the figure above look slightly different from the formulas I have shown earlier\n",
    "- That's due to the distributive law of matrix multiplication: we don't have to add the weights with the updated weights but can keep them separate\n",
    "- For instance, if $x$ is the input data, then we can write the following for regular finetuning:\n",
    "\n",
    "$$x (W+\\Delta W) = x W + x \\Delta W$$\n",
    "\n",
    "- Similarly, we can write the following for LoRA:\n",
    "\n",
    "$$x (W+A B) = x W + x A B$$\n",
    "\n",
    "- The fact that we can keep the LoRA weight matrices separate makes LoRA especially attractive\n",
    "- In practice, this means that we don't have to modify the weights of the pretrained model at all, as we can apply the LoRA matrices on the fly\n",
    "- After setting up the dataset and loading the model, we will implement LoRA in the code to make these concepts less abstract"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c7017a2-32aa-4002-a2f3-12aac293ccdf",
   "metadata": {
    "id": "8c7017a2-32aa-4002-a2f3-12aac293ccdf"
   },
   "source": [
    "## E.2 Preparing the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "669c64df-4431-4d27-834d-2bb38a01fc02",
   "metadata": {
    "id": "669c64df-4431-4d27-834d-2bb38a01fc02"
   },
   "source": [
    "- This section repeats the code from chapter 6 to load and prepare the dataset\n",
    "- Instead of repeating this code, one could open and run the chapter 6 notebook and then insert the LoRA code from section E.4 there\n",
    "- (The LoRA code was originally the last section of chapter 6 but was moved to the appendix due to the length of chapter 6)\n",
    "- In a similar fashion, we could also apply LoRA to the models in chapter 7 for instruction finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "def7c09b-af9c-4216-90ce-5e67aed1065c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "def7c09b-af9c-4216-90ce-5e67aed1065c",
    "outputId": "a67a7afe-b401-4463-c731-87025d20f72d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File downloaded and saved as sms_spam_collection/SMSSpamCollection.tsv\n"
     ]
    }
   ],
   "source": [
    "import urllib\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from previous_chapters import (\n",
    "    download_and_unzip_spam_data,\n",
    "    create_balanced_dataset,\n",
    "    random_split\n",
    ")\n",
    "# If the `previous_chapters.py` file is not available locally,\n",
    "# you can import it from the `llms-from-scratch` PyPI package.\n",
    "# For details, see: https://github.com/rasbt/LLMs-from-scratch/tree/main/pkg\n",
    "# E.g.,\n",
    "# from llms_from_scratch.ch06 import (\n",
    "#     download_and_unzip_spam_data,\n",
    "#     create_balanced_dataset,\n",
    "#     random_split\n",
    "# )\n",
    "\n",
    "\n",
    "\n",
    "url = \"https://archive.ics.uci.edu/static/public/228/sms+spam+collection.zip\"\n",
    "zip_path = \"sms_spam_collection.zip\"\n",
    "extracted_path = \"sms_spam_collection\"\n",
    "data_file_path = Path(extracted_path) / \"SMSSpamCollection.tsv\"\n",
    "\n",
    "try:\n",
    "    download_and_unzip_spam_data(url, zip_path, extracted_path, data_file_path)\n",
    "except (urllib.error.HTTPError, urllib.error.URLError, TimeoutError) as e:\n",
    "    print(f\"Primary URL failed: {e}. Trying backup URL...\")\n",
    "    url = \"https://f001.backblazeb2.com/file/LLMs-from-scratch/sms%2Bspam%2Bcollection.zip\"\n",
    "    download_and_unzip_spam_data(url, zip_path, extracted_path, data_file_path)\n",
    "\n",
    "df = pd.read_csv(data_file_path, sep=\"\\t\", header=None, names=[\"Label\", \"Text\"])\n",
    "balanced_df = create_balanced_dataset(df)\n",
    "balanced_df[\"Label\"] = balanced_df[\"Label\"].map({\"ham\": 0, \"spam\": 1})\n",
    "\n",
    "train_df, validation_df, test_df = random_split(balanced_df, 0.7, 0.1)\n",
    "train_df.to_csv(\"train.csv\", index=None)\n",
    "validation_df.to_csv(\"validation.csv\", index=None)\n",
    "test_df.to_csv(\"test.csv\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74c3c463-8763-4cc0-9320-41c7eaad8ab7",
   "metadata": {
    "id": "74c3c463-8763-4cc0-9320-41c7eaad8ab7"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import tiktoken\n",
    "from previous_chapters import SpamDataset\n",
    "\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "train_dataset = SpamDataset(\"train.csv\", max_length=None, tokenizer=tokenizer)\n",
    "val_dataset = SpamDataset(\"validation.csv\", max_length=train_dataset.max_length, tokenizer=tokenizer)\n",
    "test_dataset = SpamDataset(\"test.csv\", max_length=train_dataset.max_length, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8681adc0-6f02-4e75-b01a-a6ab75d05542",
   "metadata": {
    "id": "8681adc0-6f02-4e75-b01a-a6ab75d05542"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "num_workers = 0\n",
    "batch_size = 8\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=True,\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    dataset=val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=False,\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab7335db-e0bb-4e27-80c5-eea11e593a57",
   "metadata": {
    "id": "ab7335db-e0bb-4e27-80c5-eea11e593a57"
   },
   "source": [
    "- As a verification step, we iterate through the data loaders and check that the batches contain 8 training examples each, where each training example consists of 120 tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4dee6882-4c3a-4964-af15-fa31f86ad047",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4dee6882-4c3a-4964-af15-fa31f86ad047",
    "outputId": "2ae34de1-dd01-4f99-d2c8-ba4dca400754"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "Input batch dimensions: torch.Size([8, 120])\n",
      "Label batch dimensions torch.Size([8])\n"
     ]
    }
   ],
   "source": [
    "print(\"Train loader:\")\n",
    "for input_batch, target_batch in train_loader:\n",
    "    pass\n",
    "\n",
    "print(\"Input batch dimensions:\", input_batch.shape)\n",
    "print(\"Label batch dimensions\", target_batch.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cdd7947-7039-49bf-8a5e-c0a2f4281ca1",
   "metadata": {
    "id": "5cdd7947-7039-49bf-8a5e-c0a2f4281ca1"
   },
   "source": [
    "- Lastly, let's print the total number of batches in each dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "IZfw-TYD2zTj",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IZfw-TYD2zTj",
    "outputId": "4d19ed61-cf7a-4ec4-b822-c847dd1c5d77"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130 training batches\n",
      "19 validation batches\n",
      "38 test batches\n"
     ]
    }
   ],
   "source": [
    "print(f\"{len(train_loader)} training batches\")\n",
    "print(f\"{len(val_loader)} validation batches\")\n",
    "print(f\"{len(test_loader)} test batches\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec9aa4a-ffd2-4d9f-a835-cce1059fe604",
   "metadata": {
    "id": "dec9aa4a-ffd2-4d9f-a835-cce1059fe604"
   },
   "source": [
    "## E.3 Initializing the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f36ebdaf-810e-46a2-9ad9-e017a04051b1",
   "metadata": {
    "id": "f36ebdaf-810e-46a2-9ad9-e017a04051b1"
   },
   "source": [
    "- This section repeats the code from chapter 6 to load and prepare the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "02b3a506-3879-4258-82b5-93a5b6bafa74",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "02b3a506-3879-4258-82b5-93a5b6bafa74",
    "outputId": "b8c9b125-bb52-45d3-8071-fa5054dbf5a9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2/124M/checkpoint\n",
      "File already exists and is up-to-date: gpt2/124M/encoder.json\n",
      "File already exists and is up-to-date: gpt2/124M/hparams.json\n",
      "File already exists and is up-to-date: gpt2/124M/model.ckpt.data-00000-of-00001\n",
      "File already exists and is up-to-date: gpt2/124M/model.ckpt.index\n",
      "File already exists and is up-to-date: gpt2/124M/model.ckpt.meta\n",
      "File already exists and is up-to-date: gpt2/124M/vocab.bpe\n"
     ]
    }
   ],
   "source": [
    "from gpt_download import download_and_load_gpt2\n",
    "from previous_chapters import GPTModel, load_weights_into_gpt\n",
    "# Alternatively:\n",
    "# from llms_from_scratch.ch04 import GPTModel\n",
    "# from llms_from_scratch.ch05 import load_weights_into_gpt\n",
    "\n",
    "\n",
    "\n",
    "CHOOSE_MODEL = \"gpt2-small (124M)\"\n",
    "INPUT_PROMPT = \"Every effort moves\"\n",
    "\n",
    "BASE_CONFIG = {\n",
    "    \"vocab_size\": 50257,     # Vocabulary size\n",
    "    \"context_length\": 1024,  # Context length\n",
    "    \"drop_rate\": 0.0,        # Dropout rate\n",
    "    \"qkv_bias\": True         # Query-key-value bias\n",
    "}\n",
    "\n",
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}\n",
    "\n",
    "BASE_CONFIG.update(model_configs[CHOOSE_MODEL])\n",
    "\n",
    "model_size = CHOOSE_MODEL.split(\" \")[-1].lstrip(\"(\").rstrip(\")\")\n",
    "settings, params = download_and_load_gpt2(model_size=model_size, models_dir=\"gpt2\")\n",
    "\n",
    "model = GPTModel(BASE_CONFIG)\n",
    "load_weights_into_gpt(model, params)\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "252614cd-7ce6-4908-83e6-3761f519904e",
   "metadata": {
    "id": "252614cd-7ce6-4908-83e6-3761f519904e"
   },
   "source": [
    "- To ensure that the model was loaded corrected, let's double-check that it generates coherent text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8b6ce20c-0700-4783-8be0-4cf17c200a7f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8b6ce20c-0700-4783-8be0-4cf17c200a7f",
    "outputId": "28ccbca5-8de9-41a0-c093-da00fcbaa91c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Every effort moves you forward.\n",
      "\n",
      "The first step is to understand the importance of your work\n"
     ]
    }
   ],
   "source": [
    "from previous_chapters import (\n",
    "    generate_text_simple,\n",
    "    text_to_token_ids,\n",
    "    token_ids_to_text\n",
    ")\n",
    "\n",
    "\n",
    "text_1 = \"Every effort moves you\"\n",
    "\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(text_1, tokenizer),\n",
    "    max_new_tokens=15,\n",
    "    context_size=BASE_CONFIG[\"context_length\"]\n",
    ")\n",
    "\n",
    "print(token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8174b31b-1ab5-4115-b01c-245369da5af3",
   "metadata": {
    "id": "8174b31b-1ab5-4115-b01c-245369da5af3"
   },
   "source": [
    "- Then, we prepare the model for classification finetuning similar to chapter 6, where we replace the output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e255ce91-d73a-4854-90a4-95804928eb16",
   "metadata": {
    "id": "e255ce91-d73a-4854-90a4-95804928eb16"
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "num_classes = 2\n",
    "model.out_head = torch.nn.Linear(in_features=768, out_features=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "02e6f057-1383-4ece-8444-0a88e71ac75d",
   "metadata": {
    "id": "02e6f057-1383-4ece-8444-0a88e71ac75d"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Note:\n",
    "# Uncommenting the following lines will allow the code to run on Apple Silicon chips, if applicable,\n",
    "# which is approximately 1.2x faster than on an Apple CPU (as measured on an M3 MacBook Air).\n",
    "# However, the resulting loss values may be slightly different.\n",
    "\n",
    "#if torch.cuda.is_available():\n",
    "#    device = torch.device(\"cuda\")\n",
    "#elif torch.backends.mps.is_available():\n",
    "#    device = torch.device(\"mps\")\n",
    "#else:\n",
    "#    device = torch.device(\"cpu\")\n",
    "#\n",
    "# print(f\"Using {device} device.\")\n",
    "\n",
    "model.to(device);  # no assignment model = model.to(device) necessary for nn.Module classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e951cd6-5e42-44d2-b21f-895cb61004fe",
   "metadata": {
    "id": "8e951cd6-5e42-44d2-b21f-895cb61004fe"
   },
   "source": [
    "- Lastly, let's calculate the initial classification accuracy of the non-finetuned model (we expect this to be around 50%, which means that the model is not able to distinguish between spam and non-spam messages yet reliably)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fc7dd72c-73a2-4881-ade0-0a9605f1ab8c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fc7dd72c-73a2-4881-ade0-0a9605f1ab8c",
    "outputId": "74848515-5a49-4125-fecb-9f4bac23f812"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 46.25%\n",
      "Validation accuracy: 45.00%\n",
      "Test accuracy: 48.75%\n"
     ]
    }
   ],
   "source": [
    "from previous_chapters import calc_accuracy_loader\n",
    "# Alternatively:\n",
    "# from llms_from_scratch.ch06 import calc_accuracy_loader\n",
    "\n",
    "\n",
    "\n",
    "torch.manual_seed(123)\n",
    "train_accuracy = calc_accuracy_loader(train_loader, model, device, num_batches=10)\n",
    "val_accuracy = calc_accuracy_loader(val_loader, model, device, num_batches=10)\n",
    "test_accuracy = calc_accuracy_loader(test_loader, model, device, num_batches=10)\n",
    "\n",
    "print(f\"Training accuracy: {train_accuracy*100:.2f}%\")\n",
    "print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
    "print(f\"Test accuracy: {test_accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "398a1ec9-e2a1-43d6-bf9f-12ee54b46a7b",
   "metadata": {
    "id": "398a1ec9-e2a1-43d6-bf9f-12ee54b46a7b"
   },
   "source": [
    "## E.4 Parameter-efficient finetuning with LoRA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "652a4a82-61ef-4d0a-9858-8988e844f12c",
   "metadata": {
    "id": "652a4a82-61ef-4d0a-9858-8988e844f12c"
   },
   "source": [
    "- We begin by initializing a LoRALayer that creates the matrices $A$ and $B$, along with the `alpha` scaling hyperparameter and the `rank` ($r$) hyperparameters\n",
    "- This layer can accept an input and compute the corresponding output, as illustrated in the figure below\n",
    "\n",
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/appendix-e_compressed/lora-2.webp\" width=\"200px\">\n",
    "\n",
    "In code, this LoRA layer depicted in the figure above looks like as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2ds9ywjMwvIW",
   "metadata": {
    "id": "2ds9ywjMwvIW"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "class LoRALayer(torch.nn.Module):\n",
    "    def __init__(self, in_dim, out_dim, rank, alpha):\n",
    "        super().__init__()\n",
    "        self.A = torch.nn.Parameter(torch.empty(in_dim, rank))\n",
    "        torch.nn.init.kaiming_uniform_(self.A, a=math.sqrt(5))  # similar to standard weight initialization\n",
    "        self.B = torch.nn.Parameter(torch.zeros(rank, out_dim))\n",
    "        self.alpha = alpha\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.alpha * (x @ self.A @ self.B)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad21faa8-0614-4257-93cd-68952193e14a",
   "metadata": {
    "id": "ad21faa8-0614-4257-93cd-68952193e14a"
   },
   "source": [
    "- In the code above, `rank` is a hyperparameter that controls the inner dimension of the matrices $A$ and $B$\n",
    "- In other words, this parameter controls the number of additional parameters introduced by LoRA and is a key factor in determining the balance between model adaptability and parameter efficiency\n",
    "- The second hyperparameter, `alpha`, is a scaling hyperparameter applied to the output of the low-rank adaptation\n",
    "- It essentially controls the extent to which the adapted layer's output is allowed to influence the original output of the layer being adapted\n",
    "- This can be seen as a way to regulate the impact of the low-rank adaptation on the layer's output\n",
    "- So far, the `LoRALayer` class we implemented above allows us to transform the layer inputs $x$\n",
    "- However, in LoRA, we are usually interested in replacing existing `Linear` layers so that the weight update is applied to the existing pretrained weights, as shown in the figure below\n",
    "\n",
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/appendix-e_compressed/lora-3.webp\" width=\"200px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6d5da0-dfce-4808-b89b-29ff333f563f",
   "metadata": {
    "id": "3e6d5da0-dfce-4808-b89b-29ff333f563f"
   },
   "source": [
    "- To incorporate the original `Linear` layer weights as shown in the figure above, we implement a `LinearWithLoRA` layer below that uses the previously implemented LoRALayer and can be used to replace existing `Linear` layers in a neural network, for example, the self-attention module or feed forward modules in an LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "127d3a64-8359-4b21-b056-78d58cc75fe8",
   "metadata": {
    "id": "127d3a64-8359-4b21-b056-78d58cc75fe8"
   },
   "outputs": [],
   "source": [
    "class LinearWithLoRA(torch.nn.Module):\n",
    "    def __init__(self, linear, rank, alpha):\n",
    "        super().__init__()\n",
    "        self.linear = linear\n",
    "        self.lora = LoRALayer(\n",
    "            linear.in_features, linear.out_features, rank, alpha\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x) + self.lora(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1145a90-35ff-462c-820b-15483fa5b051",
   "metadata": {
    "id": "e1145a90-35ff-462c-820b-15483fa5b051"
   },
   "source": [
    "- Note that since we initialize the weight matrix $B$ (`self.B` in `LoRALayer`) with zero values in the LoRA layer, the matrix multiplication between $A$ and $B$ results in a matrix consisting of 0's and doesn't affect the original weights (since adding 0 to the original weights does not modify them)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e98a6d36-7bc9-434c-a7f1-533f26aff06d",
   "metadata": {
    "id": "e98a6d36-7bc9-434c-a7f1-533f26aff06d"
   },
   "source": [
    "- To try LoRA on the GPT model we defined earlier, we define a `replace_linear_with_lora` function to replace all `Linear` layers in the model with the new `LinearWithLoRA` layers\n",
    "\n",
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/appendix-e_compressed/lora-4.webp\" width=\"400px\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "WlQZ8ygqzN_g",
   "metadata": {
    "id": "WlQZ8ygqzN_g"
   },
   "outputs": [],
   "source": [
    "def replace_linear_with_lora(model, rank, alpha):\n",
    "    for name, module in model.named_children():\n",
    "        if isinstance(module, torch.nn.Linear):\n",
    "            # Replace the Linear layer with LinearWithLoRA\n",
    "            setattr(model, name, LinearWithLoRA(module, rank, alpha))\n",
    "        else:\n",
    "            # Recursively apply the same function to child modules\n",
    "            replace_linear_with_lora(module, rank, alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c172164-cdde-4489-b7d7-aaed9cc2f5f2",
   "metadata": {
    "id": "8c172164-cdde-4489-b7d7-aaed9cc2f5f2"
   },
   "source": [
    "- We then freeze the original model parameter and use the `replace_linear_with_lora` to replace the said `Linear` layers using the code below\n",
    "- This will replace the `Linear` layers in the LLM with `LinearWithLoRA` layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dbe15350-4da9-4829-9d23-98bbd3d0b1a1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dbe15350-4da9-4829-9d23-98bbd3d0b1a1",
    "outputId": "fd4c208f-854a-4701-d9d3-9d73af733364"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total trainable parameters before: 124,441,346\n",
      "Total trainable parameters after: 0\n"
     ]
    }
   ],
   "source": [
    "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Total trainable parameters before: {total_params:,}\")\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Total trainable parameters after: {total_params:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "mLk_fPq0yz_u",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mLk_fPq0yz_u",
    "outputId": "0a93b8fc-05d7-4ace-ee47-e2fc6bdd7d75"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total trainable LoRA parameters: 2,666,528\n"
     ]
    }
   ],
   "source": [
    "replace_linear_with_lora(model, rank=16, alpha=16)\n",
    "\n",
    "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Total trainable LoRA parameters: {total_params:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b6819e-ef7a-4f0d-841a-1b467496bef9",
   "metadata": {
    "id": "b8b6819e-ef7a-4f0d-841a-1b467496bef9"
   },
   "source": [
    "- As we can see, we reduced the number of trainable parameters by almost 50x when using LoRA\n",
    "- Let's now double-check whether the layers have been modified as intended by printing the model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1711be61-bb2c-466f-9b5b-24f4aa5ccd9c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1711be61-bb2c-466f-9b5b-24f4aa5ccd9c",
    "outputId": "acff8eca-3775-45a2-b62d-032a986ef037"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPTModel(\n",
      "  (tok_emb): Embedding(50257, 768)\n",
      "  (pos_emb): Embedding(1024, 768)\n",
      "  (drop_emb): Dropout(p=0.0, inplace=False)\n",
      "  (trf_blocks): Sequential(\n",
      "    (0): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_key): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_value): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (out_proj): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "          (1): GELU()\n",
      "          (2): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (1): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_key): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_value): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (out_proj): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "          (1): GELU()\n",
      "          (2): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (2): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_key): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_value): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (out_proj): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "          (1): GELU()\n",
      "          (2): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (3): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_key): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_value): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (out_proj): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "          (1): GELU()\n",
      "          (2): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (4): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_key): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_value): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (out_proj): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "          (1): GELU()\n",
      "          (2): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (5): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_key): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_value): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (out_proj): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "          (1): GELU()\n",
      "          (2): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (6): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_key): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_value): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (out_proj): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "          (1): GELU()\n",
      "          (2): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (7): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_key): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_value): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (out_proj): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "          (1): GELU()\n",
      "          (2): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (8): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_key): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_value): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (out_proj): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "          (1): GELU()\n",
      "          (2): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (9): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_key): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_value): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (out_proj): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "          (1): GELU()\n",
      "          (2): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (10): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_key): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_value): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (out_proj): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "          (1): GELU()\n",
      "          (2): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (11): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_key): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_value): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (out_proj): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "          (1): GELU()\n",
      "          (2): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (final_norm): LayerNorm()\n",
      "  (out_head): LinearWithLoRA(\n",
      "    (linear): Linear(in_features=768, out_features=2, bias=True)\n",
      "    (lora): LoRALayer()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4bbc9d7-65ec-4675-bab8-2e56eb0cfb55",
   "metadata": {
    "id": "c4bbc9d7-65ec-4675-bab8-2e56eb0cfb55"
   },
   "source": [
    "- Based on the model architecture above, we can see that the model now contains our new `LinearWithLoRA` layers\n",
    "- Also, since we initialized matrix $B$ with 0's, we expect the initial model performance to be unchanged compared to before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "DAlrb_I00VEU",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DAlrb_I00VEU",
    "outputId": "3da44ac4-230b-4358-d996-30b63f0d962a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 46.25%\n",
      "Validation accuracy: 45.00%\n",
      "Test accuracy: 48.75%\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "train_accuracy = calc_accuracy_loader(train_loader, model, device, num_batches=10)\n",
    "val_accuracy = calc_accuracy_loader(val_loader, model, device, num_batches=10)\n",
    "test_accuracy = calc_accuracy_loader(test_loader, model, device, num_batches=10)\n",
    "\n",
    "print(f\"Training accuracy: {train_accuracy*100:.2f}%\")\n",
    "print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
    "print(f\"Test accuracy: {test_accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13735b3e-f0c3-4dba-ae3d-4141b2878101",
   "metadata": {
    "id": "13735b3e-f0c3-4dba-ae3d-4141b2878101"
   },
   "source": [
    "- Let's now get to the interesting part and finetune the model by reusing the training function from chapter 6\n",
    "- The training takes about 15 minutes on a M3 MacBook Air laptop computer and less than half a minute on a V100 or A100 GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "wCParRvr0eff",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wCParRvr0eff",
    "outputId": "ce910a9c-ee89-48bb-bfa6-49c6aee1e450"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 3.820, Val loss 3.462\n",
      "Ep 1 (Step 000050): Train loss 0.396, Val loss 0.364\n",
      "Ep 1 (Step 000100): Train loss 0.111, Val loss 0.229\n",
      "Training accuracy: 97.50% | Validation accuracy: 95.00%\n",
      "Ep 2 (Step 000150): Train loss 0.135, Val loss 0.073\n",
      "Ep 2 (Step 000200): Train loss 0.008, Val loss 0.051\n",
      "Ep 2 (Step 000250): Train loss 0.022, Val loss 0.177\n",
      "Training accuracy: 97.50% | Validation accuracy: 97.50%\n",
      "Ep 3 (Step 000300): Train loss 0.086, Val loss 0.061\n",
      "Ep 3 (Step 000350): Train loss 0.021, Val loss 0.124\n",
      "Training accuracy: 100.00% | Validation accuracy: 92.50%\n",
      "Ep 4 (Step 000400): Train loss 0.088, Val loss 0.014\n",
      "Ep 4 (Step 000450): Train loss 0.010, Val loss 0.171\n",
      "Ep 4 (Step 000500): Train loss 0.015, Val loss 0.362\n",
      "Training accuracy: 100.00% | Validation accuracy: 97.50%\n",
      "Ep 5 (Step 000550): Train loss 0.049, Val loss 0.191\n",
      "Ep 5 (Step 000600): Train loss 0.049, Val loss 0.056\n",
      "Training accuracy: 100.00% | Validation accuracy: 97.50%\n",
      "Training completed in 10.20 minutes.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from previous_chapters import train_classifier_simple\n",
    "# Alternatively:\n",
    "# from llms_from_scratch.ch06 import train_classifier_simple\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5, weight_decay=0.1)\n",
    "\n",
    "num_epochs = 5\n",
    "train_losses, val_losses, train_accs, val_accs, examples_seen = train_classifier_simple(\n",
    "    model, train_loader, val_loader, optimizer, device,\n",
    "    num_epochs=num_epochs, eval_freq=50, eval_iter=5,\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time_minutes = (end_time - start_time) / 60\n",
    "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c89e82-3aa8-44c6-b046-0b16200b8e6c",
   "metadata": {
    "id": "d0c89e82-3aa8-44c6-b046-0b16200b8e6c"
   },
   "source": [
    "- Finally, let's evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bawWGijA0iF3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 308
    },
    "id": "bawWGijA0iF3",
    "outputId": "af70782a-d605-4376-fa6c-d33b38979cfa"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from previous_chapters import plot_values\n",
    "# Alternatively:\n",
    "# from llms_from_scratch.ch06 import plot_values\n",
    "\n",
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "examples_seen_tensor = torch.linspace(0, examples_seen, len(train_losses))\n",
    "\n",
    "plot_values(epochs_tensor, examples_seen_tensor, train_losses, val_losses, label=\"loss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa074723-e3f7-4f7e-a267-855531a037dc",
   "metadata": {
    "id": "aa074723-e3f7-4f7e-a267-855531a037dc"
   },
   "source": [
    "- Note that we previously calculated the accuracy values on 5 batches only via the `eval_iter=5` setting; below, we calculate the accuracies on the full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1D2awlEq0gZi",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1D2awlEq0gZi",
    "outputId": "d603eda1-d912-43eb-ec9c-af6a622510a0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 99.62%\n",
      "Validation accuracy: 97.32%\n",
      "Test accuracy: 95.67%\n"
     ]
    }
   ],
   "source": [
    "train_accuracy = calc_accuracy_loader(train_loader, model, device)\n",
    "val_accuracy = calc_accuracy_loader(val_loader, model, device)\n",
    "test_accuracy = calc_accuracy_loader(test_loader, model, device)\n",
    "\n",
    "print(f\"Training accuracy: {train_accuracy*100:.2f}%\")\n",
    "print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
    "print(f\"Test accuracy: {test_accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f87f5e6-339e-4fcf-900b-6d845d3c713d",
   "metadata": {
    "id": "1f87f5e6-339e-4fcf-900b-6d845d3c713d"
   },
   "source": [
    "- As we can see based on the relatively high accuracy values above, the LoRA finetuning was successful"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "V100",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
